{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_datasets as tfds\nimport numpy as np\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-30T05:13:02.979312Z","iopub.execute_input":"2021-06-30T05:13:02.979689Z","iopub.status.idle":"2021-06-30T05:13:09.796709Z","shell.execute_reply.started":"2021-06-30T05:13:02.979658Z","shell.execute_reply":"2021-06-30T05:13:09.795772Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"imdb_train, ds_info = tfds.load(name=\"imdb_reviews\", \n    split=\"train\", with_info=True, \n    as_supervised=True)\nimdb_test = tfds.load(name=\"imdb_reviews\", \n    split=\"test\",\n    as_supervised=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T05:13:09.798228Z","iopub.execute_input":"2021-06-30T05:13:09.798505Z","iopub.status.idle":"2021-06-30T05:14:13.380541Z","shell.execute_reply.started":"2021-06-30T05:13:09.798478Z","shell.execute_reply":"2021-06-30T05:14:13.379494Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"\u001b[1mDownloading and preparing dataset imdb_reviews/plain_text/1.0.0 (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0...\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Dl Completed...: 0 url [00:00, ? url/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f552d154ba447d98f58217ede58ede7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Dl Size...: 0 MiB [00:00, ? MiB/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08f6d9dbf05f426a9c421f9be07463ab"}},"metadata":{}},{"name":"stdout","text":"\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Shuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteVXQAX6/imdb_reviews-train.tfrecord\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f84fe56a4ca4c319f96ff32ceec0bd8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Shuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteVXQAX6/imdb_reviews-test.tfrecord\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc384549b1a047c6bb51f03372a8e2f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Shuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteVXQAX6/imdb_reviews-unsupervised.tfrecord\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d564fec5ef7e4b69a06be3300cb7315c"}},"metadata":{}},{"name":"stdout","text":"\u001b[1mDataset imdb_reviews downloaded and prepared to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# Use the default tokenizer settings\ntokenizer = tfds.features.text.Tokenizer()\nvocabulary_set = set()\nMAX_TOKENS = 0\nfor example, label in imdb_train:\n    some_tokens = tokenizer.tokenize(example.numpy())\n    if MAX_TOKENS < len(some_tokens):\n        MAX_TOKENS = len(some_tokens)\n    vocabulary_set.update(some_tokens)","metadata":{"execution":{"iopub.status.busy":"2021-06-21T03:38:03.629139Z","iopub.execute_input":"2021-06-21T03:38:03.629723Z","iopub.status.idle":"2021-06-21T03:38:11.747438Z","shell.execute_reply.started":"2021-06-21T03:38:03.629681Z","shell.execute_reply":"2021-06-21T03:38:11.746463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imdb_encoder = tfds.features.text.TokenTextEncoder(vocabulary_set,lowercase=True,tokenizer=tokenizer)\n\nvocab_size = imdb_encoder.vocab_size\n\nprint(vocab_size, MAX_TOKENS)","metadata":{"execution":{"iopub.status.busy":"2021-06-21T03:38:11.749178Z","iopub.execute_input":"2021-06-21T03:38:11.749441Z","iopub.status.idle":"2021-06-21T03:38:11.920426Z","shell.execute_reply.started":"2021-06-21T03:38:11.749414Z","shell.execute_reply":"2021-06-21T03:38:11.919085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# transformation functions to be used with the dataset\nfrom tensorflow.keras.preprocessing import sequence\n\ndef encode_pad_transform(sample):\n    encoded = imdb_encoder.encode(sample.numpy())\n    pad = sequence.pad_sequences([encoded], padding='post', maxlen=150)\n    return np.array(pad[0], dtype=np.int64)\n\ndef encode_tf_fn(sample, label):\n    encoded = tf.py_function(encode_pad_transform, inp=[sample], Tout=(tf.int64))\n    encoded.set_shape([None])\n    label.set_shape([])\n    return encoded, label","metadata":{"execution":{"iopub.status.busy":"2021-06-21T04:01:32.857324Z","iopub.execute_input":"2021-06-21T04:01:32.857824Z","iopub.status.idle":"2021-06-21T04:01:32.865052Z","shell.execute_reply.started":"2021-06-21T04:01:32.857778Z","shell.execute_reply":"2021-06-21T04:01:32.863706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoded_train = imdb_train.map(encode_tf_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n\nencoded_test = imdb_test.map(encode_tf_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2021-06-21T04:01:57.006641Z","iopub.execute_input":"2021-06-21T04:01:57.007104Z","iopub.status.idle":"2021-06-21T04:01:57.074763Z","shell.execute_reply.started":"2021-06-21T04:01:57.007073Z","shell.execute_reply":"2021-06-21T04:01:57.073894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Download GloVe**","metadata":{}},{"cell_type":"code","source":"# Download the GloVe embeddings\n!wget http://nlp.stanford.edu/data/glove.6B.zip\n!unzip glove.6B.zip","metadata":{"execution":{"iopub.status.busy":"2021-06-21T04:06:31.826927Z","iopub.execute_input":"2021-06-21T04:06:31.827285Z","iopub.status.idle":"2021-06-21T04:09:36.497415Z","shell.execute_reply.started":"2021-06-21T04:06:31.827255Z","shell.execute_reply":"2021-06-21T04:09:36.496134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dict_w2v = {}\nwith open('glove.6B.50d.txt', \"r\") as file:\n    for line in file:\n        tokens = line.split()\n        word = tokens[0]\n        vector = np.array(tokens[1:], dtype=np.float32)\n        \n        if vector.shape[0] == 50:\n            dict_w2v[word] = vector\n        else:\n            print(\"There was an issue with \" + word)\nprint(\"Dictionary Size: \", len(dict_w2v))","metadata":{"execution":{"iopub.status.busy":"2021-06-21T04:11:03.076423Z","iopub.execute_input":"2021-06-21T04:11:03.076804Z","iopub.status.idle":"2021-06-21T04:11:08.605322Z","shell.execute_reply.started":"2021-06-21T04:11:03.076773Z","shell.execute_reply":"2021-06-21T04:11:08.604073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_dim = 50\nembedding_matrix = np.zeros((imdb_encoder.vocab_size, embedding_dim))","metadata":{"execution":{"iopub.status.busy":"2021-06-21T04:11:38.33435Z","iopub.execute_input":"2021-06-21T04:11:38.334704Z","iopub.status.idle":"2021-06-21T04:11:38.339186Z","shell.execute_reply.started":"2021-06-21T04:11:38.334673Z","shell.execute_reply":"2021-06-21T04:11:38.337998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unk_cnt = 0\nunk_set = set()\nfor word in imdb_encoder.tokens:\n    embedding_vector = dict_w2v.get(word)\n    if embedding_vector is not None:\n        tkn_id = imdb_encoder.encode(word)[0]\n        embedding_matrix[tkn_id] = embedding_vector\n    else:\n        unk_cnt += 1\n        unk_set.add(word)\n# Print how many weren't found\nprint(\"Total unknown words: \", unk_cnt)","metadata":{"execution":{"iopub.status.busy":"2021-06-21T04:28:01.914021Z","iopub.execute_input":"2021-06-21T04:28:01.914826Z","iopub.status.idle":"2021-06-21T04:28:02.495437Z","shell.execute_reply.started":"2021-06-21T04:28:01.914779Z","shell.execute_reply":"2021-06-21T04:28:02.494464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Length of the vocabulary in chars\nvocab_size = imdb_encoder.vocab_size # len(chars)\n\n# Number of RNN units\nrnn_units = 64\n\n#batch size\nBATCH_SIZE=100","metadata":{"execution":{"iopub.status.busy":"2021-06-21T04:48:51.855455Z","iopub.execute_input":"2021-06-21T04:48:51.856212Z","iopub.status.idle":"2021-06-21T04:48:51.863831Z","shell.execute_reply.started":"2021-06-21T04:48:51.85617Z","shell.execute_reply":"2021-06-21T04:48:51.862694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dense\n\ndef build_model_bilstm(vocab_size, embedding_dim, rnn_units, batch_size, train_emb=False):\n    model = tf.keras.Sequential([\n        Embedding(vocab_size, embedding_dim, mask_zero=True, weights=[embedding_matrix], trainable=train_emb),\n        Bidirectional(LSTM(rnn_units, return_sequences=True, dropout=0.5)),\n        Bidirectional(LSTM(rnn_units, dropout=0.25)),\n        Dense(1, activation='sigmoid')\n    ])\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-06-21T04:52:36.067759Z","iopub.execute_input":"2021-06-21T04:52:36.068257Z","iopub.status.idle":"2021-06-21T04:52:36.074769Z","shell.execute_reply.started":"2021-06-21T04:52:36.068226Z","shell.execute_reply":"2021-06-21T04:52:36.073707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Feature Extraction**","metadata":{}},{"cell_type":"code","source":"model_fe = build_model_bilstm(\n    vocab_size = vocab_size,\n    embedding_dim=embedding_dim,\n    rnn_units=rnn_units,\n    batch_size=BATCH_SIZE)\n\nmodel_fe.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-21T04:53:04.913907Z","iopub.execute_input":"2021-06-21T04:53:04.914235Z","iopub.status.idle":"2021-06-21T04:53:08.877057Z","shell.execute_reply.started":"2021-06-21T04:53:04.914207Z","shell.execute_reply":"2021-06-21T04:53:08.875984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_fe.compile(loss='binary_crossentropy',\n    optimizer='adam',\n    metrics=['accuracy', 'Precision', 'Recall'])","metadata":{"execution":{"iopub.status.busy":"2021-06-21T05:00:12.1635Z","iopub.execute_input":"2021-06-21T05:00:12.163926Z","iopub.status.idle":"2021-06-21T05:00:12.181046Z","shell.execute_reply.started":"2021-06-21T05:00:12.163891Z","shell.execute_reply":"2021-06-21T05:00:12.179882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prefetch for performance\nencoded_train_batched = encoded_train.batch(BATCH_SIZE).prefetch(100)\n\nmodel_fe.fit(encoded_train_batched, epochs=10)","metadata":{"execution":{"iopub.status.busy":"2021-06-21T05:00:49.679778Z","iopub.execute_input":"2021-06-21T05:00:49.680188Z","iopub.status.idle":"2021-06-21T05:25:36.284898Z","shell.execute_reply.started":"2021-06-21T05:00:49.680152Z","shell.execute_reply":"2021-06-21T05:25:36.283988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_fe.evaluate(encoded_test.batch(BATCH_SIZE))","metadata":{"execution":{"iopub.status.busy":"2021-06-21T05:25:36.286344Z","iopub.execute_input":"2021-06-21T05:25:36.286901Z","iopub.status.idle":"2021-06-21T05:26:34.898428Z","shell.execute_reply.started":"2021-06-21T05:25:36.286867Z","shell.execute_reply":"2021-06-21T05:26:34.897091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Fine-tuning**","metadata":{}},{"cell_type":"code","source":"model_ft = build_model_bilstm(\n    vocab_size=vocab_size,\n    embedding_dim=embedding_dim,\n    rnn_units=rnn_units,\n    batch_size=BATCH_SIZE,\n    train_emb=True)\nmodel_ft.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-21T05:26:34.899928Z","iopub.execute_input":"2021-06-21T05:26:34.900528Z","iopub.status.idle":"2021-06-21T05:26:38.41475Z","shell.execute_reply.started":"2021-06-21T05:26:34.900461Z","shell.execute_reply":"2021-06-21T05:26:38.413894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_ft.compile(loss='binary_crossentropy',\n    optimizer='adam',\n    metrics=['accuracy', 'Precision', 'Recall'])\nmodel_ft.fit(encoded_train_batched, epochs=10)","metadata":{"execution":{"iopub.status.busy":"2021-06-21T05:26:38.416679Z","iopub.execute_input":"2021-06-21T05:26:38.416947Z","iopub.status.idle":"2021-06-21T05:54:28.584873Z","shell.execute_reply.started":"2021-06-21T05:26:38.41692Z","shell.execute_reply":"2021-06-21T05:54:28.583988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_ft.evaluate(encoded_test.batch(BATCH_SIZE))","metadata":{"execution":{"iopub.status.busy":"2021-06-21T05:54:28.586056Z","iopub.execute_input":"2021-06-21T05:54:28.586419Z","iopub.status.idle":"2021-06-21T05:55:27.214403Z","shell.execute_reply.started":"2021-06-21T05:54:28.586393Z","shell.execute_reply":"2021-06-21T05:55:27.21336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **BERT**","metadata":{}},{"cell_type":"code","source":"from transformers import BertTokenizer\n\nbert_name = 'bert-base-cased'\ntokenizer = BertTokenizer.from_pretrained(bert_name,\n    add_special_tokens=True,\n    do_lower_case=False,\n    max_length=150,\n    pad_to_max_length=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T05:11:34.818860Z","iopub.execute_input":"2021-06-30T05:11:34.819274Z","iopub.status.idle":"2021-06-30T05:11:36.017241Z","shell.execute_reply.started":"2021-06-30T05:11:34.819185Z","shell.execute_reply":"2021-06-30T05:11:36.016184Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"902974ce11bd4fae9dfde195b11f6a68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e8c7d0a08d54e13b5bd366834cde963"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/436k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6aecc1b8afeb4dcb85e7471847cb44d5"}},"metadata":{}}]},{"cell_type":"code","source":"def bert_encoder(review):\n    txt = review.numpy().decode('utf-8')\n    encoded = tokenizer.encode_plus(txt, add_special_tokens=True,\n        max_length=150,\n        pad_to_max_length=True,\n        return_attention_mask=True,\n        return_token_type_ids=True)\n\n    return encoded['input_ids'], encoded['token_type_ids'], encoded['attention_mask']","metadata":{"execution":{"iopub.status.busy":"2021-06-30T05:11:40.969170Z","iopub.execute_input":"2021-06-30T05:11:40.969511Z","iopub.status.idle":"2021-06-30T05:11:40.974832Z","shell.execute_reply.started":"2021-06-30T05:11:40.969481Z","shell.execute_reply":"2021-06-30T05:11:40.973854Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"bert_train = [bert_encoder(r) for r, l in imdb_train]\nbert_lbl = [l for r, l in imdb_train]\nbert_train = np.array(bert_train)\nbert_lbl = tf.keras.utils.to_categorical(bert_lbl, num_classes=2)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T05:17:09.189804Z","iopub.execute_input":"2021-06-30T05:17:09.190166Z","iopub.status.idle":"2021-06-30T05:20:09.774786Z","shell.execute_reply.started":"2021-06-30T05:17:09.190136Z","shell.execute_reply":"2021-06-30T05:20:09.773771Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  FutureWarning,\n","output_type":"stream"}]},{"cell_type":"code","source":"# create training and validation splits\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_val, y_train, y_val = train_test_split(bert_train,\n    bert_lbl,\n    test_size=0.2,\n    random_state=42)\nprint(x_train.shape, y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T05:20:09.777112Z","iopub.execute_input":"2021-06-30T05:20:09.777527Z","iopub.status.idle":"2021-06-30T05:20:10.470412Z","shell.execute_reply.started":"2021-06-30T05:20:09.777483Z","shell.execute_reply":"2021-06-30T05:20:10.469704Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"(20000, 3, 150) (20000, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"tr_reviews, tr_segments, tr_masks = np.split(x_train, 3, axis=1)\nval_reviews, val_segments, val_masks = np.split(x_val, 3, axis=1)\n\ntr_reviews = tr_reviews.squeeze()\ntr_segments = tr_segments.squeeze()\ntr_masks = tr_masks.squeeze()\n\nval_reviews = val_reviews.squeeze()\nval_segments = val_segments.squeeze()\nval_masks = val_masks.squeeze()","metadata":{"execution":{"iopub.status.busy":"2021-06-30T05:20:10.471674Z","iopub.execute_input":"2021-06-30T05:20:10.472052Z","iopub.status.idle":"2021-06-30T05:20:10.477481Z","shell.execute_reply.started":"2021-06-30T05:20:10.472024Z","shell.execute_reply":"2021-06-30T05:20:10.476531Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def example_to_features(input_ids,attention_masks,token_type_ids,y):\n    return {\"input_ids\": input_ids,\n        \"attention_mask\": attention_masks,\n        \"token_type_ids\": token_type_ids},y","metadata":{"execution":{"iopub.status.busy":"2021-06-30T05:22:24.993443Z","iopub.execute_input":"2021-06-30T05:22:24.993818Z","iopub.status.idle":"2021-06-30T05:22:24.998484Z","shell.execute_reply.started":"2021-06-30T05:22:24.993786Z","shell.execute_reply":"2021-06-30T05:22:24.997434Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_ds = tf.data.Dataset.from_tensor_slices((tr_reviews,\n    tr_masks, tr_segments, y_train)).\\\n    map(example_to_features).shuffle(100).batch(16)\n\nvalid_ds = tf.data.Dataset.from_tensor_slices((val_reviews,\n    val_masks, val_segments, y_val)).\\\n    map(example_to_features).shuffle(100).batch(16)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T05:23:20.469404Z","iopub.execute_input":"2021-06-30T05:23:20.469959Z","iopub.status.idle":"2021-06-30T05:23:20.751154Z","shell.execute_reply.started":"2021-06-30T05:23:20.469923Z","shell.execute_reply":"2021-06-30T05:23:20.750110Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# **Pre-built BERT classification model**","metadata":{}},{"cell_type":"code","source":"from transformers import TFBertForSequenceClassification\nbert_model = TFBertForSequenceClassification.from_pretrained(bert_name)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T05:26:05.494723Z","iopub.execute_input":"2021-06-30T05:26:05.495177Z","iopub.status.idle":"2021-06-30T05:26:43.515963Z","shell.execute_reply.started":"2021-06-30T05:26:05.495145Z","shell.execute_reply":"2021-06-30T05:26:43.515174Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85d0c2c3225e4936a70f6c29743bf137"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/527M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca95b211b98f46d0bb1a78890d26de2f"}},"metadata":{}},{"name":"stderr","text":"All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n\nSome layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\nloss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n\nbert_model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-06-30T05:29:29.983703Z","iopub.execute_input":"2021-06-30T05:29:29.984261Z","iopub.status.idle":"2021-06-30T05:29:30.235976Z","shell.execute_reply.started":"2021-06-30T05:29:29.984213Z","shell.execute_reply":"2021-06-30T05:29:30.234706Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"bert_model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-30T05:29:41.783419Z","iopub.execute_input":"2021-06-30T05:29:41.783827Z","iopub.status.idle":"2021-06-30T05:29:41.807756Z","shell.execute_reply.started":"2021-06-30T05:29:41.783790Z","shell.execute_reply":"2021-06-30T05:29:41.806436Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Model: \"tf_bert_for_sequence_classification\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nbert (TFBertMainLayer)       multiple                  108310272 \n_________________________________________________________________\ndropout_37 (Dropout)         multiple                  0         \n_________________________________________________________________\nclassifier (Dense)           multiple                  1538      \n=================================================================\nTotal params: 108,311,810\nTrainable params: 108,311,810\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Fine-tuning BERT on IMDB\")\nbert_history = bert_model.fit(train_ds, epochs=3, validation_data=valid_ds)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T05:30:19.638666Z","iopub.execute_input":"2021-06-30T05:30:19.639199Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Fine-tuning BERT on IMDB\nEpoch 1/3\n 948/1250 [=====================>........] - ETA: 1:08:16 - loss: 0.4451 - accuracy: 0.7675","output_type":"stream"}]},{"cell_type":"code","source":"# prep data for testing\nbert_test = [bert_encoder(r) for r,l in imdb_test]\nbert_tst_lbl = [l for r, l in imdb_test]\n\nbert_test2 = np.array(bert_test)\nbert_tst_lbl2 = tf.keras.utils.to_categorical (bert_tst_lbl, num_classes=2)\n\nts_reviews, ts_segments, ts_masks = np.split(bert_test2, 3, axis=1)\nts_reviews = ts_reviews.squeeze()\nts_segments = ts_segments.squeeze()\nts_masks = ts_masks.squeeze()\n\ntest_ds = tf.data.Dataset.from_tensor_slices((ts_reviews,\n    ts_masks, ts_segments, bert_tst_lbl2)).\\\n    map(example_to_features).shuffle(100).batch(16)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_model.evaluate(test_ds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Custom model with BERT**","metadata":{}},{"cell_type":"code","source":"from transformers import TFBertModel\nbert_name = 'bert-base-cased'\nbert = TFBertModel.from_pretrained(bert_name)\nbert.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_seq_len = 150\ninp_ids = tf.keras.layers.Input((max_seq_len,), dtype=tf.int64,\n    name=\"input_ids\")\natt_mask = tf.keras.layers.Input((max_seq_len,), dtype=tf.int64,\n    name=\"attention_mask\")\nseg_ids = tf.keras.layers.Input((max_seq_len,), dtype=tf.int64,\n    name=\"token_type_ids\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds.element_spec","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inp_dict = {\"input_ids\": inp_ids,\n    \"attention_mask\": att_mask,\n    \"token_type_ids\": seg_ids}\noutputs = bert(inp_dict)\n# let's see the output structure\noutputs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = tf.keras.layers.Dropout(0.2)(outputs[1])\nx = tf.keras.layers.Dense(200, activation='relu')(x)\nx = tf.keras.layers.Dropout(0.2)(x)\nx = tf.keras.layers.Dense(2, activation='sigmoid')(x)\ncustom_model = tf.keras.models.Model(inputs=inp_dict, outputs=x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\nloss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\ncustom_model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"custom_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Custom Model: Fine-tuning BERT on IMDB\")\ncustom_history = custom_model.fit(train_ds, epochs=3, validation_data=valid_ds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"custom_model.evaluate(test_ds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Make the BERT not trainable, so the pre-trained parameters will not be changed a lot. ","metadata":{}},{"cell_type":"code","source":"bert.trainable = False # don't train BERT any more\noptimizer = tf.keras.optimizers.Adam() # standard learning rate\ncustom_model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"custom_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Custom Model: Keep training custom model on IMDB\")\ncustom_history = custom_model.fit(train_ds, epochs=10, validation_data=valid_ds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"custom_model.evaluate(test_ds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}